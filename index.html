<!DOCTYPE html>
<html>

<head>
    <title>Sailesh Vemula's Portfolio</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <script src='https://kit.fontawesome.com/a076d05399.js'></script>

    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">

    <link rel='stylesheet' href='https://fonts.googleapis.com/css?family=Roboto'>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <style>
        html,
        body,
        h1,
        h2,
        h3,
        h4,
        h5,
        h6 {
            font-family: "Roboto", sans-serif
        }
    </style>
    <link rel="icon" type="image/jpg" href="media/profile_pic_icon_crop.jpg">



</head>

<script>
    function myFunction() {
        var x = document.getElementById("navDemo");
        if (x.className.indexOf("w3-show") == -1) {
            x.className += " w3-show";
        } else {
            x.className = x.className.replace(" w3-show", "");
        }
    }
</script>


<body class="w3-light-grey">

    <div class="w3-top w3-white w3-card  " style="position: fixed;overflow: hidden;" id="
        navbar">
        <!--strartttt-->
        <a class="w3-bar-item w3-button w3-padding-large w3-hide-medium w3-hide-large w3-right"
            href="javascript:void(0)" onclick="myFunction()" title="Toggle Navigation Menu"><i
                class="fa fa-bars"></i></a>
        <a href="#" class="w3-bar-item w3-button w3-wide" style="letter-spacing:4px;"><b>Home</b></a>
        <!-- Right-sided navbar links -->
        <div class="w3-right w3-hide-small" style="letter-spacing:2px;">
            <a href="#" class="w3-bar-item w3-button">Experience</a>
            <a href="#education" class="w3-bar-item w3-button">Education</a>
            <a href="#projects" class="w3-bar-item w3-button">Projects</a>
            <!-- <a href="#certificates" class="w3-bar-item w3-button"> Certificates</a> -->
            <a href="#skills" class="w3-bar-item w3-button"> Skills</a>
            <a href="#contact" class="w3-bar-item w3-button"> Contact </a>

        </div>

        <!--end-->

    </div>
    <!-- Navbar on small screens (remove the onclick attribute if you want the navbar to always show on top of the content when clicking on the links) -->
    <div id="navDemo" class="w3-bar-block w3-white w3-hide w3-hide-large w3-hide-medium w3-top" style="margin-top:46px">
        <a href="#experience" class="w3-bar-item w3-button w3-padding-large" onclick="myFunction()">Experience</a>
        <a href="#education" class="w3-bar-item w3-button w3-padding-large" onclick="myFunction()">Education</a>
        <a href="#projects" class="w3-bar-item w3-button w3-padding-large" onclick="myFunction()">Projects</a>
        <a href="#contact" class="w3-bar-item w3-button w3-padding-large" onclick="myFunction()">Contact</a>
        <!-- <a href="#certificates" class="w3-bar-item w3-button w3-padding-large" onclick="myFunction()">Certificates</a> -->
    </div>
    <!-- Page Container -->
    <div class="w3-content w3-margin-top" style="max-width:1400px;padding-top: 20px;" id="experience">

        <!-- The Grid -->
        <div class="w3-row-padding">

            <!-- Left Column -->
            <div class="w3-third">

                <div class="w3-white w3-text-black w3-card-4">
                    <div class="w3-display-container">
                        <img src="/media/profile_pic.jpg" style="width:100%" alt="Avatar">
                        <div class="w3-display-bottomleft w3-container w3-text-white">
                            <h2>Sailesh Vemula</h2>
                        </div>
                    </div>
                    <div class="w3-container">
                        <p><i class="fa fa-briefcase fa-fw w3-margin-right w3-large w3-text-teal"></i>Senior Data Engineer</p>
                        <p><i class="fa fa-home fa-fw w3-margin-right w3-large w3-text-teal"></i>Austin, Texas,
                            US</p>
                        <p><i
                                class="fa fa-envelope fa-fw w3-margin-right w3-large w3-text-teal"></i>vlvsailesh21@gmail.com
                        </p>
                        <p><i class="fa fa-phone fa-fw w3-margin-right w3-large w3-text-teal"></i>(317) 371-4658</p>
                        <a href="/media/Resume_Sailesh_Vemula.pdf" target="_blank" id="skills"><span
                                class="w3-tag w3-teal w3-round">Resume
                            </span></a>

                        <hr>

                        <p class="w3-large"><b><i class="fa fa-asterisk fa-fw w3-margin-right w3-text-teal"></i>
                                Skills</b></p>
                        <div class="w3-light-grey w3-round-xlarge w3-medium">
                            <div class="w3-container w3-center w3-round-xlarge w3-teal" style="width:93%"> Python </div>
                        </div>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge w3-medium">
                            <div class="w3-container w3-center w3-round-xlarge w3-teal" style="width:90%">
                                <div class="w3-center w3-text-white"> SQL/PostgreSQL </div>
                            </div>
                        </div>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge w3-medium">
                            <div class="w3-container w3-center w3-round-xlarge w3-teal" style="width:90%">
                                <div class="w3-center w3-text-white"> PySpark </div>
                            </div>
                        </div>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge w3-medium">
                            <div class="w3-container w3-center w3-round-xlarge w3-teal" style="width:85%">
                                <div class="w3-center w3-text-white"> Airflow </div>
                            </div>
                        </div>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge w3-medium">
                            <div class="w3-container w3-center w3-round-xlarge w3-teal" style="width:90%">
                                <div class="w3-center w3-text-white"> Git/GitCLI </div>
                            </div>
                        </div>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge w3-medium">
                            <div class="w3-container w3-center w3-round-xlarge w3-teal" style="width:65%">
                                <div class="w3-center w3-text-white"> Machine Learning </div>
                            </div>
                        </div>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge w3-medium">
                            <div class="w3-container w3-center w3-round-xlarge w3-teal" style="width:90%">
                                <div class="w3-center w3-text-white"> Tableau </div>
                            </div>
                        </div>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge w3-medium">
                            <div class="w3-container w3-center w3-round-xlarge w3-teal" style="width:85%">
                                <div class="w3-center w3-text-white"> Power BI </div>
                            </div>
                        </div>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge w3-medium">
                            <div class="w3-container w3-center w3-round-xlarge w3-teal" style="width:80%">
                                <div class="w3-center w3-text-white"> Hadoop Ecosystem </div>
                            </div>
                        </div>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge w3-medium">
                            <div class="w3-container w3-center w3-round-xlarge w3-teal" style="width:70%">
                                <div class="w3-center w3-text-white"> AWS </div>
                            </div>
                        </div>
                        <br>

                        <p class="w3-large w3-text-theme"><b><i
                                    class="fa fa-globe fa-fw w3-margin-right w3-text-teal"></i>Languages</b></p>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge">
                            <div class="w3-round-xlarge w3-teal" style="height:24px;width:100%">
                                <div class="w3-center w3-text-white">English</div>
                            </div>
                        </div>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge">
                            <div class="w3-round-xlarge w3-teal" style="height:24px;width:100%">
                                <div class="w3-center w3-text-white">Telugu</div>
                            </div>
                        </div>
                        <p></p>
                        <div class="w3-light-grey w3-round-xlarge">
                            <div class="w3-round-xlarge w3-teal" style="height:24px;width:60%">
                                <div class="w3-center w3-text-white">Hindi</div>
                            </div>
                        </div>
                        <br>
                    </div>
                </div><br>

                <!-- End Left Column -->
            </div>

            <!-- Right Column -->
            <div class="w3-twothird">
                <div class="w3-container w3-card w3-white w3-margin-bottom" style="padding-top: 20px;" id="overview">
                    <h2 class="w3-text-grey w3-padding-16"><i
                            class="fas fa-book-open fa-fw w3-margin-right w3-xxlarge w3-text-teal"></i><b> Overview </b></h2>
                    <div class="w3-container">
                        <h5 class="w3-opacity" style="display: flex;align-items: center;">
                            <b><t></t>
                                <li>Innovative Data Engineer with 6+ years of experience designing, building, and optimizing large-scale, high-availability data platforms across AWS, Azure, and hybrid cloud environments.</li>
                                <li>Expert in developing real-time streaming pipelines, ETL/ELT frameworks, and analytics solutions using PySpark, Python, SQL, Apache Kafka, Apache Flink, AWS Glue, Redshift, and Snowflake.</li>
                                <li>Proven ability to handle multi-terabyte workloads daily, integrating diverse data sources into governed lakes and warehouses to enable predictive analytics, machine learning, and BI reporting.</li>
                                <li>Skilled in data modeling, Iceberg/Delta Lake table management, query optimization, and implementing cost-efficient, performance-driven architectures that reduce processing latency from hours to minutes.</li>
                                <li>Adept at modern DataOps, CI/CD, and cloud-native best practices, ensuring secure, scalable, and compliant data ecosystems.</li>
                                <li>Committed to delivering data solutions that accelerate decision-making across enterprises.</li>
                            </b>
                        </h5>
                        <hr>
                    </div>
                </div>
                <div class="w3-container w3-card w3-white w3-margin-bottom">
                    <h2 class="w3-text-grey w3-padding-16"><i
                            class="fa fa-suitcase fa-fw w3-margin-right w3-xxlarge w3-text-teal"></i>Work Experience
                    </h2>
                    <div class="w3-container">
                        <h5 class="w3-opacity"><b><span class="w3-tag w3-teal w3-round">Data Engineer
                                </span> - Amazon </b>
                        </h5>
                        <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>March 2022 -
                            Present </h6>
                        <p>
                            <ul>
                                <li>Designed and rolled out a high-performance pipeline linking Amazon S3 and workforce 
                                    systems with AWS CDK (Python/TypeScript) and Step Functions, which cut retrieval time 
                                    from 3 hours to under 5 minutes and gave HR real-time access to workforce insights.</li>
                                <li>By integrating Airflow, DynamoDB, Redshift, and Text-Em-All API, automated daily roster 
                                    audits at a scale of 10M+ records, sending multilingual alerts that shortened compliance 
                                    resolution cycles by 60% across international teams</li>
                                <li>A 1PB/day ETL framework using AWS Glue, PySpark, and S3 brought data from SQL Server and 
                                    DynamoDB into Redshift, powering a metrics platform for 10K+ monthly users and removing 
                                    15,000+ hours of manual reporting work each month.</li>
                                <li>Introduced an attendance anomaly detection service with Python and Airflow DAGs, which 
                                    automatically raised alerts, saving 5,260+ manual hours yearly and enabling HR to respond 
                                    faster to staffing issues.</li>
                                <li>HR leaders gained visibility through QuickSight dashboards tied to Redshift and S3; these 
                                    visualizations highlighted roster completeness by site and supervisor, helping cut incomplete 
                                    profile resolution times by 40%.</li>
                                <li>For the MyVoice feedback platform, created a unified ETL process in AWS Glue and PySpark to combine 
                                    CSV, JSON, and Redshift inputs, which sped up HR follow-ups by 35% with more precise sentiment analytics.</li>
                                <li>Schema restructuring, optimized queries, and automated maintenance within Redshift led to a 45% 
                                    drop in query runtimes and materially reduced recurring compute expenses across analytics workloads.</li>
                                <li>Reliability improved when AWS EventBridge, Lambda, and CloudWatch were used to validate incoming events; 
                                    this raised overall data quality from 88% to 98%, eliminating errors that previously impacted downstream systems.</li>
                                <li>ETL throughput scaled further after tuning PySpark partitioning, job parallelism, and caching in 
                                    AWS Glue, which cut large-volume job runtimes by 30% and increased the speed of workforce analytics delivery.</li>
                                <li></li>                                
                                <!-- <li><b> Fluid –</b>Spearheaded the development of Fluid, a data-driven product
                                    optimizing workforce management:</li>
                                <div class="w3=container">
                                    <li>Engineered a robust data pipeline integrating S3 and internal sources, reducing
                                        data retrieval time from 3 hours to minutes.</li>
                                    <li>Designed and implemented an efficient ETL process, enabling seamless data
                                        visualization for the front-end team by utilizing AWS CDK
                                        with Python and TypeScript to deploy and manage complex orchestration
                                        infrastructure.</li>
                                    <li>This Enhanced employee experience by facilitating streamlined internal transfers
                                        and promotions across Amazon's global workforce.</li>
                                    <li>Technologies – AWS CDK, Step function, Lambda, Glue, EC2, S3, EventBridge,
                                        CloudWatch, Redshift, Athena, Git</li>
                                </div>
                                <li><b> Roster Audit Automation System –</b>Developed an automated system to verify
                                    associate information completeness and essential permissions,
                                    generating multilingual notifications for associates and supervisors to address
                                    missing data and streamline onboarding processes</li>
                                <div class="w3=container">
                                    <li>Engineered an automated end-to-end process integrating multiple databases (S3,
                                        DynamoDB, Redshift) and the text-em-all API,
                                        orchestrated by Airflow, to process 10 million daily records and send
                                        regionalized email notifications across Europe and North
                                        America.</li>
                                    <li>Engineered an interactive dashboard to identify and categorize individuals with
                                        incomplete information by location, language,
                                        supervisor, and site type, enabling HR associates to efficiently monitor and
                                        manage roster compliance in real-time.</li>
                                    <li>Technologies - Python, Redshift, S3, Git, Quicksight, SQL, Airflow, API’s</li>
                                </div>
                                <li><b> MyVoice: Employee Feedback System –</b>Supported the development of a
                                    company-wide employee feedback tool by designing and
                                    implementing data pipelines to provide crucial datasets, enabling warehouse
                                    employees and HR to effectively voice and address concerns</li>
                                <div class="w3=container">
                                    <li>Engineered a comprehensive data pipeline using AWS Glue, integrating diverse
                                        data sources including internal flat files (CSV, JSON),
                                        S3 buckets, and Redshift databases to enable seamless data consolidation and
                                        analysis.</li>
                                    <li>Technologies - Python, PySpark, SQL, Redshift, S3, Glue, Cloudwatch, Lambda, Git
                                    </li>
                                </div>
                                <li> <b> Data Warehouse Migration Project –</b>Engineered ETL jobs to migrate data from
                                    diverse databases (SQL Server, S3, DynamoDB) into AWS
                                    Redshift, utilizing AWS Glue, S3, CloudWatch, and Lake Formation to ensure efficient
                                    and secure data transfer and storage</li>
                                <li>Architected and implemented end-to-end data pipelines processing ~1 petabyte daily,
                                    creating a metrics tool used by 10,000 monthly users
                                    and resulting in savings of 15,000 hours per month.</li>
                                <li>Maintaining and optimizing performance of AWS services (Redshift, Step Function,
                                    Glue, Lambda) and internal ETL tool-based jobs to
                                    ensure efficient and reliable data processing workflows.</li>
                                <li>Led a two-person team in developing automated attendance tracking and alerting
                                    services using Python and Airflow, resulting in annual
                                    savings of approximately 5,260 manual hours.</li> -->
                            </ul>
                        </p>
                        <hr>
                    </div>
                    <div class="w3-container">
                        <h5 class="w3-opacity"><b><span class="w3-tag w3-teal w3-round">Data Engineer
                                </span> - Root Insurance</b>
                        </h5>
                        <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>March 2021 -
                            January
                            2022 </h6>
                        <p>
                            <ul>
                                <li>Delivered a distributed AWS Redshift data warehouse with dimensional modeling, 
                                    consolidating policy, claims, and telematics data into a single analytics source that 
                                    accelerated enterprise reporting cycles.</li>
                                <li>Automated ingestion of 6TB+ daily insurance data by orchestrating AWS Glue, Step Functions, 
                                    and S3, enabling machine learning pipelines to update risk-based pricing in near real time.</li>
                                <li>Integrated APIs, SQL Server, and CSV feeds into Redshift and Snowflake while embedding Python- 
                                    and SQL-driven data validation, maintaining 99.9% dataset accuracy for downstream analytics.</li>
                                <li>Reduced monthly infrastructure costs by $6K through migrating six high-volume workloads from SQL 
                                    Server, DynamoDB, and S3 into Redshift with compression encodings and optimized distribution strategies.</li>
                                <li>Equipped executives with 20+ Tableau dashboards that refreshed hourly from Redshift, providing timely 
                                    insight into underwriting risk trends and claims performance metrics.</li>
                                <li>Increased Redshift query throughput by 55% via schema redesign, sort/partition key adjustments, 
                                    and Workload Management tuning, improving the responsiveness of operational dashboards.</li>
                                <li>Improved fault tolerance and execution speed of EMR, Lambda, and Glue batch jobs by introducing 
                                    retry mechanisms and resource optimizations, ensuring continuous insurance data processing.</li>
                                <li>Produced enriched feature datasets in Snowflake and Redshift for the data science team, cutting 
                                    model training preparation time from multiple days to under six hours for fraud detection and claims forecasting</li>
                                <!-- <li> <b> Lifetime Value –</b> How much money can be expected to make from a customer
                                    over their lifetime with Root. It is calculated using three Machine learning models
                                    Conversion, Retention and Loss</li>
                                <div class="w3=container">
                                    <li> I and other Engineer have Created new pipeline for calculating loss along with
                                        the help of Data Scientist. Cleaned and transformed the data according to the
                                        Input requirements for the loss model and then made then available in S3 as
                                        parquet files. Depending on the
                                        date, specified predictions are calculated by the model and output is stored as
                                        parquet files. Finally, I made the files available in
                                        Database which will be later accumulated with other model outputs. Then these
                                        tables serve as inputs for analysts to make future
                                        decision. Until before the lossis calculated manually and was not accurate, now
                                        it’s about 91% accurate in calculating loss which helped
                                        in deciding the quotation amount for launching the product in new states.</li>
                                </div>
                                <li> Technologies – Redshift, Visual Studio Code, DBeaver, Terraform, GitHub, Step
                                    Function, SageMaker, Glue, Athena, Ruby</li>
                                <li> <b> On Leveling –</b> Calculating the premium for the latest version for all the
                                    quotes. By doing this, Analysts can understand the quotation amounts changing across
                                    different grains over course of time.</li>
                                <div class="w3=container">
                                    <li> Defined and created Glue Crawlers for tracking data from S3 to the Database
                                        with a team of two Engineers. Based on the requirement sheets provided by Data
                                        Analysts, Data is segregated for Driver, Vehicle and Policy level and these
                                        tables are made available as data to
                                        Tableau dashboards. Factors thus provided among different grain levels state,
                                        version helped Analysts in deciding how much should be
                                        collected as premium from individuals. After this approach, the binding
                                        percentage has increased substantially by 25 percent.</li>
                                </div>
                                <li> Technologies – Visual Studio Code, Ruby, SQL, AWS Glue, S3</li>
                                <li> Creating connectors in Fivetran, so that data from various sources can be accessed
                                    in Redshift.</li>
                                <li> Designing and Developing Architecture for Data warehouse.</li>
                                <li> Making changes to AWS resources with Orchestration tool Terraform.</li>
                                <li> Helping other teams regarding Data Warehouse during triage weeks.</li> -->
                            </ul>
                        </p>
                        <hr>
                    </div>
                    <div class="w3-container">
                        <h5 class="w3-opacity"><b><span class="w3-tag w3-teal w3-round">Data Engineer - Intern
                                </span> - Indiana Business Research Center</b>
                        </h5>
                        <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Jan 2020 - December
                            2020 </h6>
                        <p>
                            <ul>
                                <li>Developed a Microsoft SQL Server Master Data Management system with automated SSIS and 
                                    Python ETL jobs, unifying pandemic-related data from multiple international health agencies 
                                    for centralized reporting.</li>
                                <li>Migrated terabytes of healthcare records into an Azure Data Lake with optimized partitioning, 
                                    cutting query times by 40% while ensuring HIPAA compliance for sensitive patient information.</li>
                                <li>Engineered distributed data workflows on Hadoop using Spark, Hive, Flink, Sqoop, Kafka, 
                                    and HBase to process large-scale COVID-19 datasets, supporting real-time analytics for 
                                    state researchers.</li>
                                <li>Improved transformation efficiency by 35% through targeted optimization of HiveQL 
                                    and Spark SQL scripts, enabling faster availability of daily case and demographic reports.</li>
                                <li>Created Python- and R-based statistical models with interactive visualizations that informed 
                                    public health policy decisions, highlighting infection trends and vulnerable population segments.</li>
                            </ul>

                        </p>
                        <hr>
                    </div>
                    <!-- <div class="w3-container">
                        <h5 class="w3-opacity"><b><span class="w3-tag w3-teal w3-round">Data Engineer
                                </span> - Polis Center</b>
                        </h5>
                        <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Jan 2020 - Jul 2020
                        </h6>
                        <p>
                            <ul>
                                <li>Modeled and Developed a MySQL-based Data Warehouse and created a python script to
                                    get the data from NoSQL Database (MongoDB) based API service.</li>
                                <li>SAS scripts are written to create datasets by applying transformations to do
                                    statistical analysis.</li>
                                <li>R programming-based scripts are written to get the data from API services and
                                    aggregating them in one place. Gathered data is then analyzed for various Key
                                    Performance Indicators of a business.</li>
                                <li>Engaged in developing various machine learning algorithms such as linear
                                    regression, Random Forests regression, K-means clustering, KNN classification,
                                    and various other supervised learning algorithms using python libraries like
                                    Pandas, NumPy, SciPy, NLTK, TensorFlow, Scikit-learn, PyTorch, and Keras.</li>
                            </ul>
                        </p>
                        <hr>
                    </div> -->
                    <!-- <div class="w3-container">
                        <h5 class="w3-opacity"><b><span class="w3-tag w3-teal w3-round">Graduate Assistant
                                </span> - Indiana University</b>
                        </h5>
                        <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Aug 2019 - Mar 2020
                        </h6>
                        <p>
                            <ul>
                                <li>Developed a website based which will facilitate students to enroll in the program
                                    offered by the client as well as will provide help from start to end of their
                                    program, there is also an admin dashboard where the client can see analytics based
                                    on the data provided by the students (like discussions, grades). For developing this
                                    website from scratch technologies such as CSS, PHP, Html, JavaScript, SQL, are used.
                                </li>
                                <li>Developed a web interface that runs on python as a scripting language to run a
                                    machine learning algorithm in the backend using the Django framework.</li>
                            </ul>
                        </p>
                        <hr>
                    </div> -->
                    <div class="w3-container">
                        <h5 class="w3-opacity"><b><span class="w3-tag w3-teal w3-round">Data Engineer
                                </span> - Tata Consultancy Services </b>
                        </h5>
                        <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Sep 2017 - Jul 2019
                        </h6>
                        <p>
                            <ul>
                                <li>Automated data ingestion processes by building Python-based SSIS jobs, which reduced a
                                     2+ hour manual workload to minutes and ensured on-time availability of operational datasets.</li>
                                <li>Delivered dynamic Power BI and Tableau dashboards that pulled live metrics from SQL Server, 
                                    cutting manual reporting by 80% and improving KPI visibility for leadership teams.</li>
                                <li>Leveraged PySpark with SparkML on Hadoop clusters to develop forecasting models, boosting 
                                    demand planning accuracy by 20% and optimizing client inventory strategies.</li>
                                <li>Engineered high-availability ETL pipelines on Databricks Delta Lake orchestrated via 
                                    Apache Airflow, keeping analytics workloads operational with 99.9% uptime during peak usage.</li>
                                <li>Cut SQL Server query execution times by 60% through careful tuning of indexes, stored 
                                    procedures, and partition strategies, enabling faster data retrieval for analytics users.</li>
                                <li>Consolidated multiple data sources, including flat files, APIs, and relational systems, 
                                    into a centralized SQL Server data mart, streamlining reporting across diverse business units.</li>
                                <li>Partnered with cross-functional teams to design real-time drill-down dashboards, translating 
                                    complex operational needs into scalable, interactive BI solutions.</li>
                                <li>Introduced reusable Python modules for validation and transformation, improving 
                                    dataset reliability by 25% and reducing reprocessing caused by data quality issues.</li>
                            </ul>
                        </p>
                    </div>
                </div>

                <div class="w3-container w3-card w3-white w3-margin-bottom" style="padding-top: 20px;" id="education">
                    <h2 class="w3-text-grey w3-padding-16"><i
                            class="fas fa-book-open fa-fw w3-margin-right w3-xxlarge w3-text-teal"></i>Education</h2>
                    <div class="w3-container">
                        <h5 class="w3-opacity" style="display: flex;align-items: center;">
                            <b>Indiana University</b>
                            <p class="w3-text-teal" style="margin-left: 13px;">Grade :- 3.9
                            </p>
                        </h5>
                        <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>August 2019 -
                            December 2020</h6>
                        <p>Master's in Data Science</p>
                        <hr>
                    </div>
                    <div class="w3-container">
                        <h5 class="w3-opacity" style="display: flex;align-items: center;"><b>Jawaharlal Nehru
                                Technological University, Kakinada</b>
                            <p class="w3-text-teal" style="margin-left: 13px;">Grade :- 7.87
                            </p>
                        </h5>
                        <h6 class=" w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>August 2013 - May
                            2017</h6>
                        <p>Bachelor's Degree in Electronics and Communication Engineering</p>
                        <br>
                    </div>

                </div>
                <div class="w3-container w3-card w3-white w3-margin-bottom" style="padding: 20px ;" id="projects">
                    <h2 class="w3-text-grey w3-padding-16"><i
                            class="fa fa-folder-open fa-fw w3-margin-right w3-xxlarge w3-text-teal"></i>Personal
                        Projects</h2>
                    <div class="w3-container">
                        <h5 class="w3-opacity"><b>Gender Classification and Age Estimation using Convolutional Neural
                                Networks</b>&nbsp;<a
                                href="https://github.com/SaiGanesh26/Gender-Classification-Age-Estimation"><i
                                    class="material-icons" style="font-size:20px;color:teal">
                                    &#xe8a0;</i></a></h5>
                        <!-- <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Sep 2020 -
                            Dec 2020</h6> -->
                        <p>
                            <ul>
                                <li>Developed a Deep Learning Model that used more than 5 GB of image dataset to predict
                                    the
                                    person’s gender and age group and annotate over the image or live webcam feed or
                                    recorded video.</li>
                                <li>Worked on Deep Learning Libraries (TensorFlow, Keras), Graphical Processing Unit,
                                    Computer
                                    Vision Library (OpenCV), and Jupyter Notebook for developing the model.</li>
                            </ul>
                        </p>
                        <hr>
                    </div>
                    <div class="w3-container">
                        <h5 class="w3-opacity"><b>Data Visualization of US Foreign Trade Statistics</b>&nbsp;<a
                                href="/project2/"><i class="material-icons" style="font-size:20px;color:teal">
                                    &#xe8a0;</i></a></h5>
                        <!-- <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Sep 2020 - Dec
                            2020</h6> -->
                        <p>
                            <ul>
                                <li>Ingested and cleansed US Census trade datasets containing imports and exports across all states, ensuring consistency in commodity codes, units, and valuation metrics for downstream analytics.</li>
                                <li>Designed interactive dashboards highlighting trade volumes, top commodities, and value trends (in millions of USD) across geographies, enabling granular insights for economic and policy research.</li>
                                <li>Leveraged Python, Pandas, and advanced visualization libraries to implement drilldowns and time-series comparisons, accelerating trade pattern analysis for stakeholders.</li>
                            </ul>
                        </p>
                        <hr>
                    </div>
                    <div class="w3-container">
                        <h5 class="w3-opacity"><b>Object Detection and anonymizing</b>&nbsp;<a
                                href="https://github.com/sailesh21/object_detection_anonymizing"><i
                                    class="material-icons" style="font-size:20px;color:teal">
                                    &#xe8a0;</i></a></h5>
                        <!-- <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Oct 2020 - Dec
                            2020</h6> -->
                        <p>
                            <ul>
                                <li>Developed a custom-built Deep Convolutional Neural Network model to detect the
                                    person wearing a cap and hiding the identity of only that unique person wearing a
                                    cap. To read, process, and anonymize images Computer Vision Library (OpenCV) was
                                    used.</li>
                            </ul>
                        </p>
                        <hr>
                    </div>
                    <div class="w3-container">
                        <h5 class="w3-opacity"><b>Predictive Analysis Using restaurant Zomato data</b>&nbsp;<a
                                href="https://github.com/sailesh21/restaurant_rate_prediction"><i class="material-icons"
                                    style="font-size:20px;color:teal">
                                    &#xe8a0;</i></a></h5>
                        <!-- <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Jan 2020 - Apr
                            2020</h6> -->
                        <p>
                            <ul>
                                <li>Processed and transformed 1GB+ of structured and unstructured restaurant data using Spark RDDs, Spark SQL, and feature engineering to derive optimal predictors for ratings and costs.</li>
                                <li>Developed machine learning models in Python to estimate restaurant ratings based on cuisine type and cost parameters, improving prediction accuracy through hyperparameter tuning.</li>
                                <li>Applied NLP-driven sentiment analysis on customer reviews, classifying opinions as positive or negative, thereby providing actionable insights for restaurant performance optimization.</li>
                            </ul>
                        </p>
                        <hr>
                    </div>
                    <div class="w3-container">
                        <h5 class="w3-opacity"><b>Dashboard of World population statistics</b>&nbsp;<a
                                href="https://app.powerbi.com/view?r=eyJrIjoiNGI1OGZlZGUtZjBmOS00YzliLTkzOGItMjczMjhmYjZiYzQ0IiwidCI6IjExMTNiZTM0LWFlZDEtNGQwMC1hYjRiLWNkZDAyNTEwYmU5MSIsImMiOjN9&pageName=ReportSection9580f50fe94d70bce3e0"
                                target="_blank" rel="noopener noreferrer"><i class="material-icons"
                                    style="font-size:20px;color:teal">
                                    &#xe8a0;</i></a></h5>
                        <!-- <h6 class="w3-text-teal"><i class="fa fa-calendar fa-fw w3-margin-right"></i>Jan 2020 - Apr
                            2020</h6> -->
                        <p>
                            <ul>
                                <li>Consolidated global demographic datasets from multiple open data sources into a structured data warehouse using SQL for seamless integration and querying.</li>
                                <li>Developed an interactive Tableau dashboard displaying population growth, density, and demographic distribution trends across continents and countries.</li>
                                <li>Incorporated time-series analytics and calculated KPIs to track population changes over decades, enabling comparative insights between regions.</li>
                            </ul>
                        </p>

                    </div>
                </div>

                <!--
                <div class="w3-container w3-card w3-white" style="padding-top: 20px;" id="certificates">
                    <h2 class="w3-text-grey w3-padding-16"><i
                            class="fa fa-certificate fa-fw w3-margin-right w3-xxlarge w3-text-teal"></i>Learning
                        Certificates
                    </h2>
                    <div class="w3-text-black w3-container">
                        <ul>
                            <li>
                                <h5 class="w3-opacity"><b>Introduction to SQL&nbsp;</b><a
                                        href="https://www.datacamp.com/statement-of-accomplishment/course/865d4c71bb845769d7839a6a312bc005daf094a5"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Object-Oriented Programming in Python&nbsp;</b></a><a
                                        href="https://www.datacamp.com/statement-of-accomplishment/course/11454f55a002230a8bb530db6ba0e98e94864d3c"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Introduction to Data Visualization with
                                            Matplotlib&nbsp;</b></a><a
                                        href="https://www.datacamp.com/statement-of-accomplishment/course/02d0d154c65233886d99ffe8d741ba2f5069042e"><i
                                            class="material-icons" style="font-size:16px;color:teal">
                                            &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Introduction to Shell&nbsp;</b></a><a
                                        href="https://www.datacamp.com/statement-of-accomplishment/course/f42f41522fd2c027b54badcb19cedb6d5c92986d"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Writing Efficient Python Code&nbsp;</b></a><a
                                        href="https://www.datacamp.com/statement-of-accomplishment/course/777def732ef16794f7e000bde0bda3f94db64723"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Data Science for Everyone&nbsp;</b></a><a
                                        href="https://www.datacamp.com/statement-of-accomplishment/course/d41d30c7ea9b9fd0d0bc823b8ac6ea7942996b11"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Introduction to Data Engineering&nbsp;</b></a><a
                                        href="https://www.datacamp.com/statement-of-accomplishment/course/b24d881143662ee49ceec28cf075e8e9cd9b89ec"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Joining Data in SQL&nbsp;</b></a><a
                                        href="https://www.datacamp.com/statement-of-accomplishment/course/08e537b855df2717e39b8d7d881deffd4099ec9d"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Streamlined Data Ingestion with pandas&nbsp;</b></a><a
                                        href="https://www.datacamp.com/statement-of-accomplishment/course/b5b91618d89411c30a3f7ec46bdc348c48baeaa1"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            Linkedin courses
                            <li>
                                <h5 class="w3-opacity"><a><b>Data Science for Everyone&nbsp;</b></a><a href="/media/cerificates/Datascience for everyone_datacamp_completion
                                        certificate.pdf" target="_blank" rel="noopener noreferrer"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Deep Learning Face Recognition</b></a><a href="/media/cerificates/CertificateOfCompletion_Deep Learning_ Face
                                        Recognition.pdf" target="_blank" rel="noopener noreferrer"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Introduction to Deep Learning with OpenCV</b></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_Introduction to Deep Learning
                                        with OpenCV.pdf" target="_blank" rel="noopener noreferrer"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Essential Math for Machine Learning: Python</b></a></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_Essential Math for Machine
                                        Learning_ Python Edition.pdf" target="_blank" rel="noopener noreferrer"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>SQL Server integration Services</b></a></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_SQL Server Integration
                                        Services.pdf" target="_blank" rel="noopener noreferrer"><i
                                            class="material-icons" style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Learning Django</b></a></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_Learning Django.pdf"
                                        target="_blank" rel="noopener noreferrer"><i class="material-icons"
                                            style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Learning Vue.js</b></a></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_Learning Vue Js 3.pdf"
                                        target="_blank" rel="noopener noreferrer"><i class="material-icons"
                                            style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Learning Microsoft Power BI Desktop</b></a></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_Learning Microsoft Power Bi Desktop 2.pdf"
                                        target="_blank" rel="noopener noreferrer"><i class="material-icons"
                                            style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Learning Microsoft SQL Server 2019</b></a></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_Learning Microsoft SQL Server 2019.pdf"
                                        target="_blank" rel="noopener noreferrer"><i class="material-icons"
                                            style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Introduction to Spark SQL and DataFrames</b></a></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_Introduction to Spark SQL and DataFrames.pdf"
                                        target="_blank" rel="noopener noreferrer"><i class="material-icons"
                                            style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Elasticsearch Essential Training</b></a></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_Elasticsearch Essential Training.pdf"
                                        target="_blank" rel="noopener noreferrer"><i class="material-icons"
                                            style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Apache Spark Essential Training</b></a></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_Apache Spark Essential Training.pdf"
                                        target="_blank" rel="noopener noreferrer"><i class="material-icons"
                                            style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Excel 2019 Essential Training</b></a></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_Excel 2019 Essential Training.pdf"
                                        target="_blank" rel="noopener noreferrer"><i class="material-icons"
                                            style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                            <li>
                                <h5 class="w3-opacity"><a><b>Learning Excel 2019</b></a></a>
                                    <a href="/media/cerificates/CertificateOfCompletion_Learning Excel 2019.pdf"
                                        target="_blank" rel="noopener noreferrer"><i class="material-icons"
                                            style="font-size:16px;color:teal"> &#xe8f4;</i></a>
                                </h5>
                            </li>
                        </ul>
                        <br>


                    </div>

                </div>
            -->

                <!-- End Right Column -->
            </div>

            <!-- End Grid -->
        </div>

        <!-- End Page Container -->
    </div>

    <footer class="w3-container w3-teal w3-center w3-margin-top" id="contact">
        <p>Find me on social media.</p>
        <a href="https://www.facebook.com/saileshthegreat/" target="_blank"> <i
                class="fa fa-facebook-official fa-2x w3-hover-opacity" style="margin-right: 20px;"></i></a>
        <a href="https://www.instagram.com/sailesh_vemula/" target="_blank"><i
                class="fa fa-instagram fa-2x w3-hover-opacity" style="margin-right: 20px;"></i></a>
        <a href="https://twitter.com/SaileshVemula" target="_blank"><i class="fa fa-twitter fa-2x w3-hover-opacity"
                style="margin-right: 20px;"></i></a>
        <a href="https://www.linkedin.com/in/sailesh-vemula/" target="_blank"><i
                class="fa fa-linkedin fa-2x w3-hover-opacity" style="margin-right: 20px;"></i></a>
        <a href="https://github.com/sailesh21" target="_blank"><i class="fa fa-github fa-2x w3-hover-opacity"
                style="margin-right: 20px;"></i></a>

        </br>
        </br>
    </footer>


</body>

</html>



